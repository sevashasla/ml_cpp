#include "tensor/tensor.hpp"
#include "nn/models.hpp"
#include "nn/layers.hpp"
#include "nn/losses.hpp"

#include <iostream>

using namespace ml;


void test0(){
	// auto model = nn::models::Sequential<
	// 	double, 
	// 	nn::layers::Linear<double, 2, 1>
	// >();
	auto model = std::make_shared<nn::layers::Linear<double, 1, 1>>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	// Tensor<double> x(
	// 	Matrix<double>({
	// 		{0.0},
	// 		{1.0},
	// 		{2.0}
	// 	})
	// );
	// Tensor<double> y(Matrix<double>({
	// 		{0.0},
	// 		{1.0},
	// 		{2.0}
	// }));

	Tensor<double> x(
		Matrix<double>({
			{0.0},
			{1.0},
			{2.0},
			{3.0},
			{4.0}
		}), nullptr, false);
	Tensor<double> y(Matrix<double>({
			{0.0},
			{2.0},
			{4.0},
			{6.0},
			{8.0}
		}), nullptr, false);

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model->forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	cout << "weights: \n";
	cout << model->get_weight();

	cout << "bias: \n";
	cout << model->get_bias();
}


void test1(){
	// auto model = nn::models::Sequential<
	// 	double, 
	// 	nn::layers::Linear<double, 2, 1>
	// >();
	auto model = std::make_shared<nn::layers::Linear<double, 1, 1>>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	Tensor<double> x(
		Matrix<double>({
			{-0.3743157032400103},
			{2.2615914567952107},
			{-1.817402626965077},
			{-0.3368376833769455},
			{0.427090363992074},
			{1.1673731432849708},
			{-0.541317756970594},
			{-0.8586260784193804},
			{-0.485021712883056},
			{-0.5376472107543984}
		}), nullptr, false
	);
	Tensor<double> y(Matrix<double>({
			{-23.625950092615337},
			{142.7464742345267},
			{-114.71029238475006},
			{-21.26042329480674},
			{26.95696583758793},
			{73.68191979118171},
			{-34.166737328231626},
			{-54.194512015829226},
			{-30.613459930272658},
			{-33.93506085576242}
	}), nullptr, false);

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model->forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	cout << "weights: \n";
	cout << model->get_weight();

	cout << "bias: \n";
	cout << model->get_bias();
}

void test2(){
	// auto model = nn::models::Sequential<
	// 	double, 
	// 	nn::layers::Linear<double, 2, 1>
	// >();
	auto model = nn::models::Sequential<
		double,
		nn::layers::Linear<double, 1, 1>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 1, 1>
	>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	Tensor<double> x(
		Matrix<double>({
			{-0.3743157032400103},
			{2.2615914567952107},
			{-1.817402626965077},
			{-0.3368376833769455},
			{0.427090363992074},
			{1.1673731432849708},
			{-0.541317756970594},
			{-0.8586260784193804},
			{-0.485021712883056},
			{-0.5376472107543984}
		}), nullptr, false
	);
	Tensor<double> y(Matrix<double>({
			{-23.625950092615337},
			{142.7464742345267},
			{-114.71029238475006},
			{-21.26042329480674},
			{26.95696583758793},
			{73.68191979118171},
			{-34.166737328231626},
			{-54.194512015829226},
			{-30.613459930272658},
			{-33.93506085576242}
	}), nullptr, false);

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model.forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	auto pred = model.forward(x);
	auto loss = loss_fn->forward(y, pred);
	cout << "loss: \n" << loss;
}


int main() {
	cout << "----------------test0----------------\n";
	test0();
	cout << "----------------test1----------------\n";
	test1();
	cout << "----------------test2----------------\n";
	test2();

	return 0;
}

// #include <iostream>
// #include <vector>
// #include <list>
// #include <memory>
// #include "ml.h"

// using std::cin, std::cout, std::vector;


// int main(){
// 	std::shared_ptr<nn::BatchNorm> bn = std::make_shared<nn::BatchNorm>();

// 	std::vector<std::vector<double>> xv({
// 		{-8.15979402939878, -7.983845671565377}, {-7.512010748443737, -6.9287203998185465}, 
// 		{-9.811151112664817, -3.543296900154948}, {-9.837675434205272, -3.0771796262469797}, 
// 		{-10.668374789942131, -3.5757847610422853}, {-1.6173461592329268, 4.9893050825589835}, 
// 		{-10.303916516281474, -3.1253739047559583}, {-0.794152276623841, 2.104951171962879}, 
// 		{-9.484782683235093, -4.25144138246592}, {-10.20660673702788, -3.366725356181007}, 
// 		{-6.324325732561464, -9.10692870643198}, {-6.714336204993631, -9.465511515861477}, 
// 		{0.08525185826796045, 3.6452829679480585}, {-9.682077556411496, -5.975549763187208}, 
// 		{-0.7587039566841077, 3.7227620096688283}, {-9.509194357115604, -4.02892026038426}, 
// 		{-8.264150215992924, -7.289882787080023}, {-7.81213709711994, -5.349844882851342}, 
// 		{-7.4401671337478525, -8.791958512078267}, {-9.158729089778596, -3.0222464660596473}, 
// 		{-7.408735859228814, -8.109631247789798}, {-1.9819771099620271, 4.022435514174746}, 
// 		{-1.7824501314671677, 3.4707204345840927}, {-8.866083116201674, -2.433531730941006}, 
// 		{0.00024227116135100424, 5.148534029420497}, {-6.943060912666302, -7.0237441967121255}, 
// 		{-10.752110444649754, -2.7004803921299168}, {-2.406718199699357, 6.098944469870908}, 
// 		{-8.437999503904495, -7.838068712581753}, {-6.218721536072705, -9.012744045456031}, 
// 		{-11.44182630908269, -4.4578144103096555}, {-7.10357769292379, -9.769000459327339}, 
// 		{-10.220040646263461, -4.154106616293202}, {-1.8319881134989553, 3.5286314509217895}, 
// 		{-2.346732606068119, 3.561284227344442}, {-6.641387829593626, -8.075888036275485}, 
// 		{-9.697542183697275, -4.305598393856723}, {-1.340520809891421, 4.157119493365752}, 
// 		{-1.6087521511724905, 3.769494222273808}, {-2.351220657673829, 4.0097363419871845}, 
// 		{-9.877553551171472, -3.3361454376557855}, {-0.19745196890354544, 2.3463491593455075}, 
// 		{-5.943464475422075, -7.744327566687217}, {-5.437231430508833, -7.815216408049569}, 
// 		{-2.760179083161441, 5.551213578682775}, {-1.8513954583101344, 3.5188609047583252}, 
// 		{-2.3308060367853387, 4.39382526992426}, {-8.92286404810449, -6.917064074171225}, 
// 		{-2.187731658211975, 3.333521246686991}, {-7.089499139533517, -8.928389723793204}, 
// 		{-5.865964303756232, -7.968071687140101}, {-6.661390541866939, -7.559649581386978}, 
// 		{-7.331100689661361, -8.120613557930687}, {-7.684883027605868, -7.455196070551826}, 
// 		{-5.7911262534989625, -6.186126355369311}, {-11.140230701675241, -4.302691269776082}, 
// 		{-0.5257904636130821, 3.3065986015291307}, {-1.9274479855745354, 4.9368453355813475}, 
// 		{-0.757969185355724, 4.908984207745029}, {-9.799412783526332, -3.834339901555746}, 
// 		{-9.767617768288718, -3.19133736705118}, {-9.806797018985636, -1.8530934108843624}, 
// 		{-9.712125178398843, -3.0682073830924765}, {-2.7768702545837973, 4.640905566660254}
// 	});

// 	Matrix<double> x(xv);
// 	Matrix<double> out1 = bn->forward(x);


// 	return 0;
// }



// #include "ml.h"
// // #include "matrix.h"


// using std::cin, std::cout;

// //regression
// int main(){
// 	nn::Sequential<
// 		nn::Linear<1, 2>,
// 		nn::BatchNorm,
// 		nn::ReLU,
// 		nn::Linear<2, 1>
// 	> seq;

// 	std::shared_ptr<nn::nnLayer> loss_fn_ptr = std::make_shared<nn::MSELoss>();

// 	std::vector<std::vector<double>> xv({
// 		{-0.04381816897592824},
// 		{0.8846223804995846},
// 		{1.7886284734303186},
// 		{-0.08274148148245977},
// 		{-0.47721803035950267},
// 		{-0.27738820251439905},
// 		{-1.8634927033644908},
// 		{0.09649746807200862},
// 		{-0.6270006768238473},
// 		{-1.3138647533626822},
// 		{-0.35475897926898675},
// 		{0.8813180422075299},
// 		{-0.40467741460089085},
// 		{0.43650985051198943},
// 		{0.05003364217686021},
// 		{1.7095730636529485}
// 	});

// 	std::vector<std::vector<double>> yv({
// 		{-1.670626913715927},
// 		{23.21992947894406},
// 		{44.74147340593384},
// 		{-2.8491525584404362},
// 		{-13.698883165744842},
// 		{-7.034784453213415},
// 		{-46.492521725130295},
// 		{1.9409106021341014},
// 		{-15.235925525008472},
// 		{-33.39421280669383},
// 		{-10.400489537772946},
// 		{22.477710629189346},
// 		{-11.185958265378694},
// 		{10.677689159254532},
// 		{1.558446919564437},
// 		{45.37155111231997}
// 	});

// 	Matrix<double> x(xv);
// 	Matrix<double> y(yv);


// 	int num_epoch = 10000;
// 	while(num_epoch){

// 		Matrix<double> out = seq.forward(x);
// 		Matrix<double> loss = loss_fn_ptr->forward(y, out);
// 		loss.backward();

// 		loss.make_step(1e-3);		
// 		loss.zero_grad();
// 		loss.break_graph();


// 		if(num_epoch % 50 == 0){
// 			cout << loss;
// 		}
// 		--num_epoch;
// 	}

// 	Matrix<double> pred = seq.forward(x);
// 	for(size_t i = 0; i < pred.num_rows(); ++i){
// 		cout << pred[i][0] << "\t" << y[i][0] << "\n";
// 	}


// 	return 0;
// }


// // classification
// // int main(){
// // 	constexpr size_t num_classes = 3;

// // 	nn::Sequential<
// // 		nn::Linear<2, 4>,
// // 		// nn::BatchNorm,
// // 		nn::ReLU,
// // 		nn::Linear<4, num_classes>
// // 	> seq;

// // 	std::shared_ptr<nn::nnLayer> loss_fn_ptr = std::make_shared<nn::CrossEntropyLoss<num_classes>>();

// // 	std::vector<std::vector<double>> xv({
// // 		{-8.15979402939878, -7.983845671565377}, {-7.512010748443737, -6.9287203998185465}, 
// // {-9.811151112664817, -3.543296900154948}, {-9.837675434205272, -3.0771796262469797}, 
// // {-10.668374789942131, -3.5757847610422853}, {-1.6173461592329268, 4.9893050825589835}, 
// // {-10.303916516281474, -3.1253739047559583}, {-0.794152276623841, 2.104951171962879}, 
// // {-9.484782683235093, -4.25144138246592}, {-10.20660673702788, -3.366725356181007}, 
// // {-6.324325732561464, -9.10692870643198}, {-6.714336204993631, -9.465511515861477}, 
// // {0.08525185826796045, 3.6452829679480585}, {-9.682077556411496, -5.975549763187208}, 
// // {-0.7587039566841077, 3.7227620096688283}, {-9.509194357115604, -4.02892026038426}, 
// // {-8.264150215992924, -7.289882787080023}, {-7.81213709711994, -5.349844882851342}, 
// // {-7.4401671337478525, -8.791958512078267}, {-9.158729089778596, -3.0222464660596473}, 
// // {-7.408735859228814, -8.109631247789798}, {-1.9819771099620271, 4.022435514174746}, 
// // {-1.7824501314671677, 3.4707204345840927}, {-8.866083116201674, -2.433531730941006}, 
// // {0.00024227116135100424, 5.148534029420497}, {-6.943060912666302, -7.0237441967121255}, 
// // {-10.752110444649754, -2.7004803921299168}, {-2.406718199699357, 6.098944469870908}, 
// // {-8.437999503904495, -7.838068712581753}, {-6.218721536072705, -9.012744045456031}, 
// // {-11.44182630908269, -4.4578144103096555}, {-7.10357769292379, -9.769000459327339}, 
// // {-10.220040646263461, -4.154106616293202}, {-1.8319881134989553, 3.5286314509217895}, 
// // {-2.346732606068119, 3.561284227344442}, {-6.641387829593626, -8.075888036275485}, 
// // {-9.697542183697275, -4.305598393856723}, {-1.340520809891421, 4.157119493365752}, 
// // {-1.6087521511724905, 3.769494222273808}, {-2.351220657673829, 4.0097363419871845}, 
// // {-9.877553551171472, -3.3361454376557855}, {-0.19745196890354544, 2.3463491593455075}, 
// // {-5.943464475422075, -7.744327566687217}, {-5.437231430508833, -7.815216408049569}, 
// // {-2.760179083161441, 5.551213578682775}, {-1.8513954583101344, 3.5188609047583252}, 
// // {-2.3308060367853387, 4.39382526992426}, {-8.92286404810449, -6.917064074171225}, 
// // {-2.187731658211975, 3.333521246686991}, {-7.089499139533517, -8.928389723793204}, 
// // {-5.865964303756232, -7.968071687140101}, {-6.661390541866939, -7.559649581386978}, 
// // {-7.331100689661361, -8.120613557930687}, {-7.684883027605868, -7.455196070551826}, 
// // {-5.7911262534989625, -6.186126355369311}, {-11.140230701675241, -4.302691269776082}, 
// // {-0.5257904636130821, 3.3065986015291307}, {-1.9274479855745354, 4.9368453355813475}, 
// // {-0.757969185355724, 4.908984207745029}, {-9.799412783526332, -3.834339901555746}, 
// // {-9.767617768288718, -3.19133736705118}, {-9.806797018985636, -1.8530934108843624}, 
// // {-9.712125178398843, -3.0682073830924765}, {-2.7768702545837973, 4.640905566660254}
// // 	});

// // 	std::vector<std::vector<double>> yv({
// // 		{2}, {2}, {1}, {1}, 
// // 		{1}, {0}, {1}, {0}, 
// // 		{1}, {1}, {2}, {2}, 
// // 		{0}, {1}, {0}, {1}, 
// // 		{2}, {1}, {2}, {1}, 
// // 		{2}, {0}, {0}, {1}, 
// // 		{0}, {2}, {1}, {0}, 
// // 		{2}, {2}, {1}, {2}, 
// // 		{1}, {0}, {0}, {2}, 
// // 		{1}, {0}, {0}, {0}, 
// // 		{1}, {0}, {2}, {2}, 
// // 		{0}, {0}, {0}, {2}, 
// // 		{0}, {2}, {2}, {2}, 
// // 		{2}, {2}, {2}, {1}, 
// // 		{0}, {0}, {0}, {1}, 
// // 		{1}, {1}, {1}, {0}
// // 	});

// // 	Matrix<double> x(xv);
// // 	Matrix<double> y_fresh(yv);
// // 	Matrix<double> y = static_cast<Matrix<double>>(nn::OneHot<num_classes>(y_fresh));


// // 	int num_epoch = 3000;
// // 	while(num_epoch){

// // 		Matrix<double> out = seq.forward(x);
// // 		// Matrix<double> out = lin_ptr->forward(x);
// // 		Matrix<double> loss = loss_fn_ptr->forward(y, out);
// // 		loss.backward();

// // 		loss.make_step(1e-3);		
// // 		loss.zero_grad();
// // 		loss.break_graph();


// // 		// if(num_epoch % 50 == 0){
// // 		// 	cout << loss;
// // 		// }
// // 		--num_epoch;
// // 	}

// // 	Matrix<double> out = seq.forward(x);
// // 	Matrix<double> pred_classes = static_cast<Matrix<double>>(nn::predict<num_classes>(out));
// // 	cout << nn::accuracy(y_fresh, pred_classes);
// // 	return 0;
// // }




