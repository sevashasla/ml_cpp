#include "tensor/tensor.hpp"
#include "nn/models.hpp"
#include "nn/layers.hpp"
#include "nn/losses.hpp"
#include "nn/metrics.hpp"
#include "nn/preprocessing.hpp"
#include "nn/postprocessing.hpp"
#include "tqdm_like/tqdm_like.hpp"

#include <iostream>

using namespace ml;
using std::cout;

void test0(){
	auto model = std::make_shared<nn::layers::Linear<double, 1, 1>>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	Tensor<double> x(
		Matrix<double>({
			{0.0},
			{1.0},
			{2.0},
			{3.0},
			{4.0}
		}), nullptr, false);
	Tensor<double> y(Matrix<double>({
			{0.0},
			{2.0},
			{4.0},
			{6.0},
			{8.0}
		}), nullptr, false);

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model->forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	cout << "weights: \n";
	cout << model->get_weight();

	cout << "bias: \n";
	cout << model->get_bias();

	auto pred = model->forward(x);
	auto loss = loss_fn->forward(y, pred);

	cout << "loss: " << loss;
	cout << "mape: " << metrics::meanAveragePercentageError(y, pred);
}

void test1(){
	auto model = std::make_shared<nn::layers::Linear<double, 1, 1>>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	Tensor<double> x(
		Matrix<double>({
			{-0.3743157032400103},
			{2.2615914567952107},
			{-1.817402626965077},
			{-0.3368376833769455},
			{0.427090363992074},
			{1.1673731432849708},
			{-0.541317756970594},
			{-0.8586260784193804},
			{-0.485021712883056},
			{-0.5376472107543984}
		}), nullptr, false
	);
	Tensor<double> y(Matrix<double>({
			{-23.625950092615337},
			{142.7464742345267},
			{-114.71029238475006},
			{-21.26042329480674},
			{26.95696583758793},
			{73.68191979118171},
			{-34.166737328231626},
			{-54.194512015829226},
			{-30.613459930272658},
			{-33.93506085576242}
	}), nullptr, false);

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model->forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	auto pred = model->forward(x);
	auto loss = loss_fn->forward(y, pred);
	cout << "loss: " << loss;
	cout << "mape: " << metrics::meanAveragePercentageError(y, pred);
}

void test2(){
	auto model = nn::models::Sequential<
		double,
		nn::layers::Linear<double, 1, 2>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 2, 1>
	>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	Tensor<double> x(
		Matrix<double>({
			{1.5792128155073915},
			{0.6476885381006925},
			{-0.4694743859349521},
			{0.7674347291529088},
			{0.5425600435859647},
			{-0.23413695694918055},
			{-0.13826430117118466},
			{1.5230298564080254},
			{0.4967141530112327},
			{-0.23415337472333597},
		}), nullptr, false
	);
	Tensor<double> y(Matrix<double>({
			{28.71403183926645},
			{11.776594720057336},
			{-8.536216482719636},
			{13.953879446181778},
			{9.86509621329011},
			{-4.257194451925509},
			{-2.5139902026363337},
			{27.692485369682437},
			{9.031503458257015},
			{-4.257492968050251},
	}), nullptr, false);


	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model.forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	auto pred = model.forward(x);
	auto loss = loss_fn->forward(y, pred);
	cout << "loss: " << loss;
}

void test3(){
	auto model = nn::models::Sequential<
		double,
		nn::layers::Linear<double, 1, 2>,
		nn::layers::BatchNorm<double>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 2, 1>
	>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	Tensor<double> x(
		Matrix<double>({
			{1.5792128155073915},
			{0.6476885381006925},
			{-0.4694743859349521},
			{0.7674347291529088},
			{0.5425600435859647},
			{-0.23413695694918055},
			{-0.13826430117118466},
			{1.5230298564080254},
			{0.4967141530112327},
			{-0.23415337472333597},
		}), nullptr, false
	);
	Tensor<double> y(Matrix<double>({
			{28.71403183926645},
			{11.776594720057336},
			{-8.536216482719636},
			{13.953879446181778},
			{9.86509621329011},
			{-4.257194451925509},
			{-2.5139902026363337},
			{27.692485369682437},
			{9.031503458257015},
			{-4.257492968050251},
	}), nullptr, false);


	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model.forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	auto pred = model.forward(x);
	auto loss = loss_fn->forward(y, pred);
	cout << "loss: " << loss;
}

void test4(){
	nn::models::SingleLayer<double, nn::layers::Linear<double, 1, 1>> model;
	nn::models::SingleLayer<double, nn::losses::MSELoss<double>> loss_fn;

	Tensor<double> x(
		Matrix<double>({
			{0.0},
			{1.0},
			{2.0},
			{3.0},
			{4.0}
		}), nullptr, false);
	Tensor<double> y(Matrix<double>({
			{0.0},
			{2.0},
			{4.0},
			{6.0},
			{8.0}
		}), nullptr, false);

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model.forward(x);
		auto loss = loss_fn.forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	auto pred = model.forward(x);
	auto loss = loss_fn.forward(y, pred);
	
	cout << "loss: " << loss;
}

void test5(){
	// stupid classification

	Tensor<double> x(
		Matrix<double>({
		{1.5792128155073915},
		{0.6476885381006925},
		{-0.4694743859349521},
		{0.7674347291529088},
		{0.5425600435859647},
		{-0.23413695694918055},
		{-0.13826430117118466},
		{1.5230298564080254},
		{0.4967141530112327},
		{-0.23415337472333597}	
	}), nullptr, false);

	Tensor<size_t> y_fresh(
		Matrix<size_t>({
			{1},
			{1},
			{0},
			{1},
			{1},
			{0},
			{0},
			{1},
			{1},
			{0}	
	}), nullptr, false);

	Tensor<double> y(
		static_cast<Matrix<double>>(preprocessing::OneHot<2>(y_fresh)), 
		nullptr, 
		false);

	nn::models::SingleLayer<double, nn::layers::Linear<double, 1, 2>> model;
	nn::models::SingleLayer<double, nn::losses::CrossEntropyLoss<double, 2>> loss_fn;

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model.forward(x);
		auto loss = loss_fn.forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	auto pred = model.forward(x);
	auto loss = loss_fn.forward(y, pred);
	auto pred_classes = postprocessing::predict<2>(pred);

	cout << "loss: " << loss;
	cout << "accuracy: " << metrics::accuracy<double>(static_cast<Matrix<size_t>&>(y_fresh), pred_classes);
	cout << "probabilities:\n";
	cout << postprocessing::predictProba<2, double>(pred);
}

void test6(){
	Tensor<double> x(
		Matrix<double>({
		{1.5792128155073915},
		{0.6476885381006925},
		{-0.4694743859349521},
		{0.7674347291529088},
		{0.5425600435859647},
		{-0.23413695694918055},
		{-0.13826430117118466},
		{1.5230298564080254},
		{0.4967141530112327},
		{-0.23415337472333597}	
	}), nullptr, false);

	Tensor<size_t> y_fresh(
		Matrix<size_t>({
			{1},
			{1},
			{0},
			{1},
			{1},
			{0},
			{0},
			{1},
			{1},
			{0}	
	}), nullptr, false);

	Tensor<double> y(
		static_cast<Matrix<double>>(preprocessing::OneHot<2>(y_fresh)), 
		nullptr, 
		false);

	auto model = nn::models::Sequential<
		double,
		nn::layers::Linear<double, 1, 3>,
		nn::layers::BatchNorm<double>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 3, 2>
	>();

	nn::models::SingleLayer<double, nn::losses::CrossEntropyLoss<double, 2>> loss_fn;

	for(int epoch = 0; epoch < 10000; ++epoch) {
		auto pred = model.forward(x);
		auto loss = loss_fn.forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	}

	auto pred = model.forward(x);
	auto loss = loss_fn.forward(y, pred);
	auto pred_classes = postprocessing::predict<2>(pred);

	cout << "loss: " << loss;
	cout << "accuracy: " << metrics::accuracy<double>(static_cast<Matrix<size_t>&>(y_fresh), pred_classes);
	cout << "probabilities:\n";
	cout << postprocessing::predictProba<2, double>(pred);
}

void test7(){
	Tensor<double> x(
		Matrix<double>({
			{0.6795977489346758, -0.7153037092599682, -1.0777447779293061, 1.088950596967366, 0.06428001909546277},
			{-1.142970297830623, 0.058208718445999896, 0.1537251059455279, 0.3853173797288368, -0.883857436201133},
			{-0.7537361643574896, -0.2453881160028705, 1.8967929826539474, 0.4127809269364983, 0.82206015999449},
			{0.5425600435859647, -0.4694743859349521, 0.7674347291529088, -0.23413695694918055, 1.5792128155073915},
			{-0.2916937497932768, -0.600638689918805, 0.37569801834567196, 0.11092258970986608, -1.1509935774223028},
			{-1.763040155362734, 0.3436182895684614, 1.0571222262189157, -0.7198442083947086, -0.4606387709597875},
			{-0.23415337472333597, 1.5230298564080254, 0.6476885381006925, 0.4967141530112327, -0.13826430117118466},
			{0.19686123586912352, -1.3281860488984305, -1.9596701238797756, -1.2208436499710222, 0.2088635950047554},
			{0.852433334796224, -0.661786464768388, 0.18645431476942764, 0.6339190223180112, -2.025142586657607},
			{-0.16128571166600914, -0.8022772692216189, -0.3427145165267695, -1.4153707420504142, -0.42064532276535904},
			{3.852731490654721, 0.5150476863060479, 0.5137859509122088, -0.9378250399151228, 0.5150352672086598},
			{0.5132674331133561, -0.5297602037670388, 0.32875110965968446, -0.5017570435845365, 0.9154021177020741},
			{1.030999522495951, 0.6116762888408679, -0.6769220003059587, 0.324083969394795, -0.38508228041631654},
			{0.29307247329868125, 0.23225369716100355, -0.6800247215784908, 0.25049285034587654, 0.3464482094969757},
			{2.720169166589619, -0.2646568332379561, 1.4535340771573169, 0.8271832490360238, 0.01300189187790702},
			{-0.5034756541161992, 0.09965136508764122, -0.5662977296027719, 2.1904556258099785, -0.9905363251306883},
			{-1.7249178325130328, -1.913280244657798, 0.24196227156603412, -0.46341769281246226, -0.46572975357025687},
			{-0.5443827245251827, -1.4247481862134568, 0.06752820468792384, 1.465648768921554, -0.22577630048653566},
			{-1.9875689146008928, 0.0917607765355023, -0.2990073504658674, 0.8219025043752238, 0.08704706823817121},
			{-2.6197451040897444, 1.5646436558140062, -0.03582603910995154, 0.36139560550841393, 1.5380365664659692},
			{-0.9194242342338032, 0.4735924306351816, -1.0623037137261049, -1.5506634310661327, 0.06856297480602733},
			{-0.47193186578943347, -1.6127158711896517, 0.6862601903745135, 2.3146585666735087, -1.867265192591748},
			{-0.6451197546051243, 0.36163602504763415, 1.0035328978920242, 1.356240028570823, -0.07201012158033385},
			{0.822544912103189, -1.0577109289559004, -0.013497224737933921, -0.6017066122293969, 1.8522781845089378},
			{-1.2308643164339552, 0.8135172173696698, -0.3220615162056756, 1.5499344050175394, -0.7832532923362371},
			{0.40498171096095553, 1.7654542402810969, -0.6533292325737119, -0.3345012358409484, -0.4749453111609562},
			{0.9633761292443218, -0.8206823183517105, 1.158595579007404, -0.9746816702273214, 0.787084603742452},
			{-1.4785219903674274, -0.3011036955892888, -0.11564828238824053, 0.7384665799954104, 0.1713682811899705},
			{0.25988279424842353, 0.1846338585323042, -1.6074832345612275, 0.22745993460412942, 1.307142754282428},
			{0.08187413938632256, -0.48536354782910346, -0.23681860674000887, 0.7589692204932674, -0.7728252145375718},
			{-1.4123037013352915, -0.9080240755212109, 0.3142473325952739, -0.5622875292409727, -1.0128311203344238},
			{-1.5148472246858646, -0.846793718068405, -0.07282891265687277, 0.714000494092092, 0.47323762457354485},
			{-0.39210815313215763, -0.3276621465977682, -0.7020530938773524, 0.09707754934804039, 0.9686449905328892},
			{-0.3152692446403456, 0.651391251305798, 0.9540017634932023, 0.570890510693167, 1.135565640180599},
			{-0.07444591576616721, 0.25755039072276437, 0.17457781283183896, 0.4040508568145384, 1.8861859012105302},
			{-1.377669367957091, 1.053802052034903, 1.083051243175277, 0.3577873603482833, 0.5607845263682344},
			{-0.23458713337514692, 0.00511345664246089, 0.26105527217988933, -1.4635149481321186, 0.29612027706457605},
			{-0.8084936028931876, -0.5182702182736474, 1.477894044741516, -0.21967188783751193, 0.3571125715117464},
			{0.29698467323318606, 0.5219415656168976, -1.3204566130842763, 0.7818228717773104, -1.236950710878082},
			{0.27669079933001905, 0.3411519748166439, -0.0771017094141042, -0.8895144296255233, -0.8158102849654383},
			{0.5868570938002703, -1.4018510627922809, 1.4027943109360992, 0.7910319470430469, -0.9093874547947389},
			{2.1439440893253257, -0.6516003476058171, 0.045571839903813784, -0.7303666317171367, 0.21645858958197486},
			{0.812525822394198, -1.1962066240806708, -1.1063349740060282, -0.47917423784528995, -0.18565897666381712},
			{0.9755451271223592, 0.33126343140356396, -0.3092123758512146, 0.9312801191161986, -0.8392175232226385},
			{-0.2234627853258509, 0.4824724152431853, -1.0708924980611123, 0.6256673477650062, -0.8571575564162826},
			{-1.2002964070557762, 0.8657551941701215, 0.5049872789804571, -0.7925207384327007, -0.11473644146689901},
			{-0.19236096478112252, 2.463242112485286, 0.06023020994102644, -1.9187712152990415, -0.026513875449216878},
			{0.7519330326867741, 1.1428228145150205, -1.168678037619532, 0.30154734233361247, -0.03471176970524331},
			{0.6565536086338297, -1.1913034972026486, 0.4738329209117875, -0.7143514180263678, 1.8657745111447566},
			{0.173180925851182, -1.245738778711988, 0.21409374413020396, -0.4465149520670211, 0.8563987943234723}
		}), nullptr, false
	);

	Tensor<double> y(Matrix<double>({
			{-26.58819466279737},
			{14.30859740464597},
			{231.05662163187856},
			{106.98359004190964},
			{7.137208699196578},
			{37.72438972701916},
			{91.89987018408922},
			{-256.2590567445118},
			{0.8340532296917877},
			{-136.72738631660718},
			{5.919907188461284},
			{22.493647561264957},
			{-57.905578701469246},
			{-36.63692211856491},
			{194.3901053716395},
			{63.18931687346377},
			{-24.50842705952384},
			{94.69731288234746},
			{32.11714789274757},
			{68.12239890761454},
			{-207.58290718696102},
			{164.18156952933333},
			{179.44609720611172},
			{10.126053334622048},
			{53.489434464549234},
			{-101.42486343559453},
			{69.63318854599872},
			{42.44936958252712},
			{-103.73019230588595},
			{7.603907304557629},
			{-29.937117286052356},
			{52.03788130192275},
			{-33.336394708165656},
			{161.65873114557374},
			{98.87511229159038},
			{145.5921236640526},
			{-56.36021028284459},
			{136.22784571290924},
			{-102.76256690286529},
			{-90.38427736111761},
			{162.6563306611637},
			{-36.15249597786688},
			{-148.457151826518},
			{8.149354277475963},
			{-82.28918650775074},
			{-12.677406017214397},
			{-122.27518447947644},
			{-92.47394207815948},
			{50.52563749746511},
			{13.071061994481864}
	}), nullptr, false);

	auto model = nn::models::Sequential<
		double,
		nn::layers::Linear<double, 5, 8>,
		nn::layers::BatchNorm<double>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 8, 8>,
		nn::layers::BatchNorm<double>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 8, 1>
	>();
	auto loss_fn = std::make_shared<nn::losses::MSELoss<double>>();

	tqdm_like::tqdm_like(0, 10000, 1, [&](){
		auto pred = model.forward(x);
		auto loss = loss_fn->forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();
	});

	auto pred = model.forward(x);
	auto loss = loss_fn->forward(y, pred);
	cout << "loss: " << loss;
	cout << "mape: " << metrics::meanAveragePercentageError(y, pred);
}

void test8(){
	constexpr size_t NUM_CLASSES = 3;

	Tensor<double> x(
		Matrix<double>({
		{1.6777538372714285, 1.1110980872114011, 1.299125342397713, -0.9002272968473451, 0.45214811748491046},
		{0.7465501119191706, -0.1542441648401963, -0.3171387201980296, -0.24904277121779683, 0.6838501777375456},
		{-0.020565932474791448, -1.4190568675104036, -0.6713406259761396, -2.7047386772231534, -1.9757267839330157},
		{-0.7471089247416328, -0.819352048103106, -0.08646664886434197, -1.7513950066285315, -2.1673281414099157},
		{1.4864440566482007, 1.0364359602641902, 0.9005756889838988, -0.0459487817594707, 1.1185977002940035},
		{0.7238807975854726, -1.2009493827906663, -1.5955845439706775, -0.38213753998264066, 1.062716941610835},
		{0.13699547804854242, 1.1135975850727466, 1.1554592586094483, 0.5463114077609841, 0.12663990344520115},
		{0.7122274335055084, 1.5156370866107423, 1.000294050805387, 1.7253061336961593, 1.7447473237289373},
		{3.170242545050125, -1.2726663108106744, -1.259432706007061, -3.140801589824615, 1.1566461541019337},
		{0.3250294959452843, 0.7541982875292504, 1.1837256093518551, -0.7464948373405449, -0.7555014825989586},
		{-0.11824015621585698, 0.8126534038602807, 0.96385489768534, 0.2682506454884508, -0.2856965456585284},
		{-1.0810716499721844, 2.160385348930946, 2.721689097662697, 0.8820352729985492, -1.4667029837095356},
		{-1.8503879093952829, -0.5058968425372887, -0.7514326917653137, 1.5635172469475593, -0.30214895244505324},
		{1.591402585356072, 2.105932756492358, 2.54458310748846, -0.7687872203066151, -0.026116272999202383},
		{0.3850248550455091, 0.970094480272574, 0.8917138570005261, 0.5587331647690037, 0.49541656262844724},
		{-1.6053333204745688, -1.7875705161818274, -1.1708122513167647, -1.5104827952359685, -2.4111851138228517},
		{1.1819845951153847, 0.8184453573073268, 0.8488509378860847, -0.36848934870768224, 0.5635218441467482},
		{1.3589652616962475, 1.1636883269682379, 0.8038041456813162, 0.6608696048283362, 1.6082454587660338},
		{1.4455778839568774, 0.7664377709768145, 0.4116067942160271, 0.32202519491077675, 1.5749719418429882},
		{0.6234539993612708, 1.621497511395461, 0.9482017783731204, 2.2336437376566556, 2.092862651137045},
		{-1.7387557216312686, -1.9709687558699662, -1.897459947129609, -0.25008012612433217, -1.2205950964313426},
		{-2.4728441247761803, -0.7030666798660937, -0.5863804632018572, 1.017090647015048, -1.4524240523311056},
		{3.4154269316872163, 1.5771004599235137, 1.5080388771755988, -1.218625950667318, 1.8797969507783432},
		{2.9506807706838285, 1.2927463927357905, 1.4412079156600752, -1.5926849530868785, 1.1248758752337715},
		{0.23633228149164787, -0.31918012429726833, -0.542321372046627, 0.14742089372182154, 0.5792463221760089},
		{1.5447150599514956, 0.11169882408608944, -0.0978548164915205, -0.5299709409239892, 1.1795749324500864},
		{-1.3415587866655205, 1.862242352067542, 2.119279352891309, 1.589974108466761, -0.9095783018466221},
		{-1.1691678748106333, -2.5973475947709153, -2.7379355654450785, -0.566696888131933, -0.5635009552311201},
		{-0.04286045050782874, 0.9517907374333064, 1.5178620405601344, -0.6760096709097417, -1.20657964058543},
		{-1.676069987486765, -2.078652182819026, -1.6069845765001858, -1.3104054548518689, -2.144417911692746},
		{-0.29138698822170783, 0.004955144101657492, 0.18877066104600848, -0.2246671817319803, -0.5574885091417889},
		{0.7167117628935484, 0.9149231979067041, 1.2733225789377556, -0.7498627615485212, -0.3944783446974778},
		{0.6509910590904724, -1.4162947958434553, -0.7209049616979664, -3.057618221460445, -1.560779718203384},
		{1.509927217667927, -0.3940301318217009, -0.4687352932549227, -1.1623243135043122, 0.7726459809330337},
		{0.45218224714590416, 1.0831299761794242, 0.9831906808509046, 0.6373963957439759, 0.5920057668004438},
		{-2.280592370650708, -1.9141082822573467, -1.3896349232208582, -0.8947931643125303, -2.506520565874366},
		{2.0525050750199014, 0.22224893040287286, 0.27579089800230316, -1.4418202687233086, 0.7986677540988268},
		{3.13214210860894, 0.3469751156812934, 0.2710509454760939, -1.821376278478258, 1.5901187466419866},
		{0.48542481410020427, 0.63887374240538, 1.2524679540268688, -1.374107436572893, -1.1352454566723513},
		{-2.637841011796747, 0.9583385097617121, 1.367470803120714, 1.5503241433367607, -1.9640260391333924},
		{-0.4463728609668556, -1.019695598544528, -0.8066449935188791, -0.867314308414094, -0.8456918908911923},
		{0.5629751866363186, 1.2987205695246142, 0.9648865407005032, 1.2567035353822709, 1.221438838234263},
		{0.7821109672087867, 1.036517674076434, 0.9445378625104308, 0.3522145334861375, 0.7096734608134312},
		{0.15175177890870908, -0.6045533711086359, 0.1035081543008336, -2.1899992294849815, -1.6867492441331278},
		{1.823140428772337, -1.9511129726995755, -2.174934404753186, -2.0713376803222947, 1.0275169891065175},
		{3.2186004264030137, 0.30861589631531033, -0.21868032970330464, -0.8387098529583823, 2.6819828674190207},
		{1.492115146962908, 0.29933515386050463, 0.2884215118839384, -0.8380895346415127, 0.7181174032138813},
		{-1.2459648277325193, -1.8759571009526887, -1.326886840090686, -1.6652220601284995, -2.109285836819546},
		{1.5079937471713407, -1.0160781618894863, -1.2305787008873077, -1.2447315277659257, 1.0076848649987324},
		{-3.2514678769489262, 1.295690043807694, 1.4402100931584028, 2.840143946922941, -1.5589741558969035}
	}), nullptr, false);

	Tensor<size_t> y_fresh(
		Matrix<size_t>({
			{1},
			{0},
			{2},
			{2},
			{1},
			{0},
			{0},
			{0},
			{0},
			{1},
			{2},
			{2},
			{1},
			{0},
			{0},
			{2},
			{1},
			{0},
			{0},
			{0},
			{2},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{2},
			{2},
			{1},
			{2},
			{2},
			{0},
			{0},
			{2},
			{0},
			{1},
			{2},
			{1},
			{2},
			{0},
			{0},
			{2},
			{0},
			{1},
			{0},
			{2},
			{2},
			{1}
	}), nullptr, false);

	Tensor<double> y(
		static_cast<Matrix<double>>(preprocessing::OneHot<NUM_CLASSES>(y_fresh)), 
		nullptr, 
		false);

	auto model = nn::models::Sequential<
		double,
		nn::layers::Linear<double, 5, 8>,
		nn::layers::BatchNorm<double>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 8, 8>,
		nn::layers::BatchNorm<double>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 8, NUM_CLASSES>
	>();

	nn::models::SingleLayer<double, nn::losses::CrossEntropyLoss<double, NUM_CLASSES>> loss_fn;

	tqdm_like::tqdm_like(0, 10000, 1, [&](){
		auto pred = model.forward(x);
		auto loss = loss_fn.forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();		
	});

	auto pred = model.forward(x);
	auto loss = loss_fn.forward(y, pred);
	auto pred_classes = postprocessing::predict<NUM_CLASSES>(pred);

	cout << "loss: " << loss;
	cout << "accuracy: " << metrics::accuracy<double>(y_fresh, pred_classes);
	cout << "probabilities:\n";
	cout << postprocessing::predictProba<NUM_CLASSES, double>(pred);
}


// test on dataset_iris
void test9(){
	constexpr size_t NUM_CLASSES = 3;

	Tensor<double> x(
		Matrix<double>({
		{5.1, 3.5, 1.4, 0.2},
		{4.9, 3.0, 1.4, 0.2},
		{4.7, 3.2, 1.3, 0.2},
		{4.6, 3.1, 1.5, 0.2},
		{5.0, 3.6, 1.4, 0.2},
		{5.4, 3.9, 1.7, 0.4},
		{4.6, 3.4, 1.4, 0.3},
		{5.0, 3.4, 1.5, 0.2},
		{4.4, 2.9, 1.4, 0.2},
		{4.9, 3.1, 1.5, 0.1},
		{5.4, 3.7, 1.5, 0.2},
		{4.8, 3.4, 1.6, 0.2},
		{4.8, 3.0, 1.4, 0.1},
		{4.3, 3.0, 1.1, 0.1},
		{5.8, 4.0, 1.2, 0.2},
		{5.7, 4.4, 1.5, 0.4},
		{5.4, 3.9, 1.3, 0.4},
		{5.1, 3.5, 1.4, 0.3},
		{5.7, 3.8, 1.7, 0.3},
		{5.1, 3.8, 1.5, 0.3},
		{5.4, 3.4, 1.7, 0.2},
		{5.1, 3.7, 1.5, 0.4},
		{4.6, 3.6, 1.0, 0.2},
		{5.1, 3.3, 1.7, 0.5},
		{4.8, 3.4, 1.9, 0.2},
		{5.0, 3.0, 1.6, 0.2},
		{5.0, 3.4, 1.6, 0.4},
		{5.2, 3.5, 1.5, 0.2},
		{5.2, 3.4, 1.4, 0.2},
		{4.7, 3.2, 1.6, 0.2},
		{4.8, 3.1, 1.6, 0.2},
		{5.4, 3.4, 1.5, 0.4},
		{5.2, 4.1, 1.5, 0.1},
		{5.5, 4.2, 1.4, 0.2},
		{4.9, 3.1, 1.5, 0.2},
		{5.0, 3.2, 1.2, 0.2},
		{5.5, 3.5, 1.3, 0.2},
		{4.9, 3.6, 1.4, 0.1},
		{4.4, 3.0, 1.3, 0.2},
		{5.1, 3.4, 1.5, 0.2},
		{5.0, 3.5, 1.3, 0.3},
		{4.5, 2.3, 1.3, 0.3},
		{4.4, 3.2, 1.3, 0.2},
		{5.0, 3.5, 1.6, 0.6},
		{5.1, 3.8, 1.9, 0.4},
		{4.8, 3.0, 1.4, 0.3},
		{5.1, 3.8, 1.6, 0.2},
		{4.6, 3.2, 1.4, 0.2},
		{5.3, 3.7, 1.5, 0.2},
		{5.0, 3.3, 1.4, 0.2},
		{7.0, 3.2, 4.7, 1.4},
		{6.4, 3.2, 4.5, 1.5},
		{6.9, 3.1, 4.9, 1.5},
		{5.5, 2.3, 4.0, 1.3},
		{6.5, 2.8, 4.6, 1.5},
		{5.7, 2.8, 4.5, 1.3},
		{6.3, 3.3, 4.7, 1.6},
		{4.9, 2.4, 3.3, 1.0},
		{6.6, 2.9, 4.6, 1.3},
		{5.2, 2.7, 3.9, 1.4},
		{5.0, 2.0, 3.5, 1.0},
		{5.9, 3.0, 4.2, 1.5},
		{6.0, 2.2, 4.0, 1.0},
		{6.1, 2.9, 4.7, 1.4},
		{5.6, 2.9, 3.6, 1.3},
		{6.7, 3.1, 4.4, 1.4},
		{5.6, 3.0, 4.5, 1.5},
		{5.8, 2.7, 4.1, 1.0},
		{6.2, 2.2, 4.5, 1.5},
		{5.6, 2.5, 3.9, 1.1},
		{5.9, 3.2, 4.8, 1.8},
		{6.1, 2.8, 4.0, 1.3},
		{6.3, 2.5, 4.9, 1.5},
		{6.1, 2.8, 4.7, 1.2},
		{6.4, 2.9, 4.3, 1.3},
		{6.6, 3.0, 4.4, 1.4},
		{6.8, 2.8, 4.8, 1.4},
		{6.7, 3.0, 5.0, 1.7},
		{6.0, 2.9, 4.5, 1.5},
		{5.7, 2.6, 3.5, 1.0},
		{5.5, 2.4, 3.8, 1.1},
		{5.5, 2.4, 3.7, 1.0},
		{5.8, 2.7, 3.9, 1.2},
		{6.0, 2.7, 5.1, 1.6},
		{5.4, 3.0, 4.5, 1.5},
		{6.0, 3.4, 4.5, 1.6},
		{6.7, 3.1, 4.7, 1.5},
		{6.3, 2.3, 4.4, 1.3},
		{5.6, 3.0, 4.1, 1.3},
		{5.5, 2.5, 4.0, 1.3},
		{5.5, 2.6, 4.4, 1.2},
		{6.1, 3.0, 4.6, 1.4},
		{5.8, 2.6, 4.0, 1.2},
		{5.0, 2.3, 3.3, 1.0},
		{5.6, 2.7, 4.2, 1.3},
		{5.7, 3.0, 4.2, 1.2},
		{5.7, 2.9, 4.2, 1.3},
		{6.2, 2.9, 4.3, 1.3},
		{5.1, 2.5, 3.0, 1.1},
		{5.7, 2.8, 4.1, 1.3},
		{6.3, 3.3, 6.0, 2.5},
		{5.8, 2.7, 5.1, 1.9},
		{7.1, 3.0, 5.9, 2.1},
		{6.3, 2.9, 5.6, 1.8},
		{6.5, 3.0, 5.8, 2.2},
		{7.6, 3.0, 6.6, 2.1},
		{4.9, 2.5, 4.5, 1.7},
		{7.3, 2.9, 6.3, 1.8},
		{6.7, 2.5, 5.8, 1.8},
		{7.2, 3.6, 6.1, 2.5},
		{6.5, 3.2, 5.1, 2.0},
		{6.4, 2.7, 5.3, 1.9},
		{6.8, 3.0, 5.5, 2.1},
		{5.7, 2.5, 5.0, 2.0},
		{5.8, 2.8, 5.1, 2.4},
		{6.4, 3.2, 5.3, 2.3},
		{6.5, 3.0, 5.5, 1.8},
		{7.7, 3.8, 6.7, 2.2},
		{7.7, 2.6, 6.9, 2.3},
		{6.0, 2.2, 5.0, 1.5},
		{6.9, 3.2, 5.7, 2.3},
		{5.6, 2.8, 4.9, 2.0},
		{7.7, 2.8, 6.7, 2.0},
		{6.3, 2.7, 4.9, 1.8},
		{6.7, 3.3, 5.7, 2.1},
		{7.2, 3.2, 6.0, 1.8},
		{6.2, 2.8, 4.8, 1.8},
		{6.1, 3.0, 4.9, 1.8},
		{6.4, 2.8, 5.6, 2.1},
		{7.2, 3.0, 5.8, 1.6},
		{7.4, 2.8, 6.1, 1.9},
		{7.9, 3.8, 6.4, 2.0},
		{6.4, 2.8, 5.6, 2.2},
		{6.3, 2.8, 5.1, 1.5},
		{6.1, 2.6, 5.6, 1.4},
		{7.7, 3.0, 6.1, 2.3},
		{6.3, 3.4, 5.6, 2.4},
		{6.4, 3.1, 5.5, 1.8},
		{6.0, 3.0, 4.8, 1.8},
		{6.9, 3.1, 5.4, 2.1},
		{6.7, 3.1, 5.6, 2.4},
		{6.9, 3.1, 5.1, 2.3},
		{5.8, 2.7, 5.1, 1.9},
		{6.8, 3.2, 5.9, 2.3},
		{6.7, 3.3, 5.7, 2.5},
		{6.7, 3.0, 5.2, 2.3},
		{6.3, 2.5, 5.0, 1.9},
		{6.5, 3.0, 5.2, 2.0},
		{6.2, 3.4, 5.4, 2.3},
		{5.9, 3.0, 5.1, 1.8}
	}), nullptr, false);

	Tensor<size_t> y_fresh(
		Matrix<size_t>({
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{0},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{1},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2},
			{2}
	}), nullptr, false);

	Tensor<double> y(
		static_cast<Matrix<double>>(preprocessing::OneHot<NUM_CLASSES>(y_fresh)), 
		nullptr, 
		false);

	auto model = nn::models::Sequential<
		double,
		nn::layers::Linear<double, 4, 8>,
		nn::layers::BatchNorm<double>,
		nn::layers::ReLU<double>,
		nn::layers::Linear<double, 8, NUM_CLASSES>
	>();

	nn::models::SingleLayer<double, nn::losses::CrossEntropyLoss<double, NUM_CLASSES>> loss_fn;

	tqdm_like::tqdm_like(0, 10000, 1, [&](){
		auto pred = model.forward(x);
		auto loss = loss_fn.forward(y, pred);
		loss.backward();
		loss.make_step(1e-3);
		loss.zero_grad();
		loss.break_graph();		
	});

	auto pred = model.forward(x);
	auto loss = loss_fn.forward(y, pred);
	auto pred_classes = postprocessing::predict<NUM_CLASSES>(pred);

	cout << "loss: " << loss;
	cout << "accuracy: " << metrics::accuracy<double>(y_fresh, pred_classes);
	cout << "probabilities:\n";
	cout << postprocessing::predictProba<NUM_CLASSES, double>(pred);
}

int main() {
	cout << "----------------test0----------------\n";
	test0();
	cout << "----------------test1----------------\n";
	test1();
	cout << "----------------test2----------------\n";
	test2();
	cout << "----------------test3----------------\n";
	test3();
	cout << "----------------test4----------------\n";
	test4();
	cout << "----------------test5----------------\n";
	test5();
	cout << "----------------test6----------------\n";
	test6();
	cout << "----------------test7----------------\n";
	test7();
	cout << "----------------test8----------------\n";
	test8();
	cout << "----------------test9----------------\n";
	test8();

	return 0;
}
